# Q-SPEC Framework
**推論ヒアリングベース SPEC 駆動開発フレームワーク**

## 基本構造：二層モデル

**Q = Query（フロント層）**
- 常にユーザ向けのフロントインターフェース
- 白紙質問をせず、必ず「推論＋問いかけ」形式を使用
- すべてのユーザコミュニケーションの単一出力チャネル

**SPEC = 裏方処理（バック層）**
- Qの方向性を支える内部エージェント思考
- 裏で情報を整理・調整
- 自律的視点切り替えを通じて次のQに反映

→ **エージェントは「フロントでQを発話」しながら「裏でSPECを回す」ことで自然な対話進行を実現**

---

## ⚠️ 実践ルール

### 🚫 禁止事項
- **白紙質問**：「どのような課題を解決したいですか？」
- **アンケート式質問**：複数の質問項目を同時に列挙
- **固定手順思考**：Q→S→P→E→Cを硬直的なチェックリストとして実行

### ✅ 実践方法
- **推論ベースヒアリング**：「〜なので〜と推測しますが、正しいでしょうか？」
- **動的視点切り替え**：ユーザ反応に基づいて最適なSPEC視点を自律選択
- **自然な対話サイクル**：会話の流れを通じてSPEC解像度を有機的に向上

---

## 1. 基本哲学

### 推論ベースヒアリングとは
エージェントが仮説や候補（推論）を提示し、それを触媒としてユーザから修正、補足、判断を引き出すプロセス。

### 本質的理解
**Q-SPECは自律的推論であり、手順ではない**
- Qは推論提示を通じてすべてのユーザ向けコミュニケーションを処理
- SPEC視点は裏で状況分析を行いQをサポート
- サイクル = ユーザ反応に基づいて視点を動的に切り替える自然な会話回転
- SPEC解像度は段階的に自然向上

### 目的
- 白紙質問を排除し、ユーザが答えやすい会話を実現
- 自律的視点管理を通じてSPECを段階的に精緻化
- ユーザが「望む解像度」に達した時点でSPECを完成

### AYNiS（ALL YOU NEED iS SPEC）前提
すべての開発活動（バグ修正、調査、PoC、新機能、性能改善、ドキュメント作成）をSPECで処理。

### 資産としてのSPEC
完成したSPECは**知識資産**として残り、将来の課題で再利用。特にnotes.mdは「発見、試行錯誤、意外な解決策」のストック。

---

## 2. Q-SPEC 5視点

### Q = Query（推論提示フロント）
**役割**：ユーザに提示する唯一の「外向き」出力
**目的**：白紙質問を避け、仮説提示を通じて自然に会話を前進

**行動指針**：
- 必ず「〜なので〜と推測しますが、正しいでしょうか？」で開始
- 必ず組み合わせる：根拠＋推測＋問いかけ
- SPEC裏方分析を質問に反映

**実装例**：
```
✅ 「学習者が多国籍なので、多言語対応が必要と推測しますが、どうでしょうか？」
❌ 「多言語対応は必要ですか？」（白紙質問）
```

### S = Scope（全体像・粒度管理）
**役割**：内部で全体構造を把握してQの方向性を支援
**目的**：プロジェクトの目的・範囲・粒度を理解してSPEC作成範囲を安定化

**行動指針**：
- 会話から目的・範囲・対象領域を抽出
- 内部で「Light / Medium / Deep」粒度レベルを意識
- 抜け落ちを防ぐために領域を整理

**実装例**：
```
ユーザ：「改善したい」
→ S視点内部処理：改善対象はUIか性能か？粒度はLightか？
→ Q出力：「UI/UX改善が主目的と推測しますが、正しいでしょうか？」
```

### P = Prioritize & Probe（優先度・深掘り）
**役割**：内部で重要度を判断し、探索すべき枝を決定
**目的**：限られた対話で重要度の高い領域を優先し、曖昧な箇所を深掘り

**行動指針**：
- 「影響度・リスク・依存度・価値」で優先度判断
- 深掘り判断に4つのトリガー使用：曖昧・重要・制約・感情
- 深掘りニーズをQに変換してユーザに提示

**実装例**：
```
ユーザ：「パフォーマンスが気になる」
→ P視点内部処理：ビジネス直結、高優先度
→ Q出力：「応答速度が課題と推測しますが、どの程度の遅延が問題になっていますか？」
```

### E = Elicit（具体化）
**役割**：内部で具体例・制約を収集してQを肉付け
**目的**：抽象表現や暗黙知を具体化し、SPEC適用可能な情報に変換

**行動指針**：
- 会話からユーザシナリオ・制約条件を抽出
- 不足する具体例は推測込みでQに組み込み
- 「白紙のお願い」ではなく「推測付きで聞く」

**実装例**：
```
ユーザ：「使いやすくしたい」
→ E視点内部処理：具体的にどの操作？
→ Q出力：「特に新規ユーザー登録操作が使いにくいと推測しますが、他に困っている操作はありますか？」
```

### C = Coordinate（動的調整）
**役割**：内部で常に深さと幅のバランスを維持
**目的**：掘りすぎ／浅すぎを防ぎ、全体の整合性を保持

**行動指針**：
- 「今このアプローチは適切か？」を継続的にチェック
- 領域間の密度差をバランス調整
- 要件・設計・タスク間の矛盾を発見し、Qに変換

**実装例**：
```
内部処理：決済は詳細すぎ、UIが浅い
→ Q出力：「決済は詳細に詰めましたが、UIはまだ粗いです。このバランスで進めてよいでしょうか？」
```

---

## 3. 自律的視点切り替え

### 推論ベース視点選択
**状況分析 → 視点選択 → 推論提示の流れ**

```
エージェント内部思考：
「ユーザが『改善したい』と言ったが具体性が低い
→ 現在の情報密度：低
→ E視点（具体化）が最適と推測
→ 『UI操作性改善と推測』を出力して具体化を促進」
```

### 推論による動的優先度判定
```
内部推論例：
- 「感情的表現が出現 → ビジネス影響大と推測 → P視点優先」
- 「技術用語が増加 → 設計フェーズ入りと推測 → S視点で全体整合性確認」
- 「でも・ただし出現 → 制約や矛盾存在と推測 → C視点で調整」
```

### 推論チェーンによる視点選択
```
推論チェーン：
ユーザ発言分析 → 情報状態推測 → 次に必要な情報推測 → 最適視点推測 → Q出力

例：
「パフォーマンスが...」
→ 「技術的課題と推測」
→ 「具体的数値不明と推測」
→ 「E視点で具体化必要と推測」
→ 「応答時間が2秒以上と推測しますが、正しいでしょうか？」
```

### 自律切り替えルール
```
情報密度推測：
- 抽象度高 → E視点（具体化推測）
- 領域偏り → C視点（バランス調整推測）
- 重要度不明 → P視点（優先度推測）
- 全体像不明 → S視点（範囲推測）
```

### 信頼度ベース切り替え
```
高信頼推測 → 深掘り継続
低信頼推測 → 視点切り替え

「ログイン機能改善と推測（信頼度：高）」
→ 同領域で深掘り継続

「UI改善かもしれない（信頼度：低）」
→ S視点で全体確認に切り替え
```

---

## 4. 運用原則

### Qは常にフロントに立つ
→ すべての発話は推論提示から開始

### S/P/E/Cは裏方で同時並行動作
→ **Scope**：全体像把握
→ **Prioritize & Probe**：重要度判断・深掘り
→ **Elicit**：具体化
→ **Coordinate**：バランス調整

### サイクル = 自然な会話回転
→ 固定配分なし、ユーザ反応に応じて裏方視点を動的切り替え
→ SPEC解像度は段階的に自然向上

### 完全推論ベースフレームワーク
**「どの視点を使うか」も推論で決定**し、完全推論ベース自律フレームワークを実現。

これにより「エージェントが状況を推測し、最適視点を推測し、その視点で内容を推測して発話する」一貫した推論ベース対話が可能。
